{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully-Connected Neural Nets\n",
    "In the previous homework you implemented a fully-connected two-layer neural network on CIFAR-10. The implementation was simple but not very modular since the loss and gradient were computed in a single monolithic function. This is manageable for a simple two-layer network, but would become impractical as we move to bigger models. Ideally we want to build networks using a more modular design so that we can implement different layer types in isolation and then snap them together into models with different architectures.\n",
    "\n",
    "In this exercise we will implement fully-connected networks using a more modular approach. For each layer we will implement a `forward` and a `backward` function. The `forward` function will receive inputs, weights, and other parameters and will return both an output and a `cache` object storing data needed for the backward pass, like this:\n",
    "\n",
    "```python\n",
    "def layer_forward(x, w):\n",
    "  \"\"\" Receive inputs x and weights w \"\"\"\n",
    "  # Do some computations ...\n",
    "  z = # ... some intermediate value\n",
    "  # Do some more computations ...\n",
    "  out = # the output\n",
    "   \n",
    "  cache = (x, w, z, out) # Values we need to compute gradients\n",
    "   \n",
    "  return out, cache\n",
    "```\n",
    "\n",
    "The backward pass will receive upstream derivatives and the `cache` object, and will return gradients with respect to the inputs and weights, like this:\n",
    "\n",
    "```python\n",
    "def layer_backward(dout, cache):\n",
    "  \"\"\"\n",
    "  Receive derivative of loss with respect to outputs and cache,\n",
    "  and compute derivative with respect to inputs.\n",
    "  \"\"\"\n",
    "  # Unpack cache values\n",
    "  x, w, z, out = cache\n",
    "  \n",
    "  # Use values in cache to compute derivatives\n",
    "  dx = # Derivative of loss with respect to x\n",
    "  dw = # Derivative of loss with respect to w\n",
    "  \n",
    "  return dx, dw\n",
    "```\n",
    "\n",
    "After implementing a bunch of layers this way, we will be able to easily combine them to build classifiers with different architectures.\n",
    "\n",
    "In addition to implementing fully-connected networks of arbitrary depth, we will also explore different update rules for optimization, and introduce Dropout as a regularizer and Batch Normalization as a tool to more efficiently optimize deep networks.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As usual, a bit of setup\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.classifiers.fc_net import *\n",
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "from cs231n.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from cs231n.solver import Solver\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_val: ', (1000, 3, 32, 32))\n",
      "('y_test: ', (1000,))\n",
      "('X_test: ', (1000, 3, 32, 32))\n",
      "('y_train: ', (49000,))\n",
      "('y_val: ', (1000,))\n",
      "('X_train: ', (49000, 3, 32, 32))\n"
     ]
    }
   ],
   "source": [
    "# Load the (preprocessed) CIFAR10 data.\n",
    "\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in list(data.items()):\n",
    "  print(('%s: ' % k, v.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine layer: foward\n",
    "Open the file `cs231n/layers.py` and implement the `affine_forward` function.\n",
    "\n",
    "Once you are done you can test your implementaion by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_forward function:\n",
      "difference:  9.76984946819e-10\n"
     ]
    }
   ],
   "source": [
    "# Test the affine_forward function\n",
    "\n",
    "num_inputs = 2\n",
    "input_shape = (4, 5, 6)\n",
    "output_dim = 3\n",
    "\n",
    "input_size = num_inputs * np.prod(input_shape)\n",
    "weight_size = output_dim * np.prod(input_shape)\n",
    "\n",
    "x = np.linspace(-0.1, 0.5, num=input_size).reshape(num_inputs, *input_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=weight_size).reshape(np.prod(input_shape), output_dim)\n",
    "b = np.linspace(-0.3, 0.1, num=output_dim)\n",
    "\n",
    "out, _ = affine_forward(x, w, b)\n",
    "correct_out = np.array([[ 1.49834967,  1.70660132,  1.91485297],\n",
    "                        [ 3.25553199,  3.5141327,   3.77273342]])\n",
    "\n",
    "# Compare your output with ours. The error should be around 1e-9.\n",
    "print('Testing affine_forward function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine layer: backward\n",
    "Now implement the `affine_backward` function and test your implementation using numeric gradient checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_backward function:\n",
      "dx error:  5.39910036865e-11\n",
      "dw error:  9.9042118654e-11\n",
      "db error:  2.41228675681e-11\n"
     ]
    }
   ],
   "source": [
    "# Test the affine_backward function\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(10, 2, 3)\n",
    "w = np.random.randn(6, 5)\n",
    "b = np.random.randn(5)\n",
    "dout = np.random.randn(10, 5)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: affine_forward(x, w, b)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: affine_forward(x, w, b)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: affine_forward(x, w, b)[0], b, dout)\n",
    "\n",
    "_, cache = affine_forward(x, w, b)\n",
    "dx, dw, db = affine_backward(dout, cache)\n",
    "\n",
    "# The error should be around 1e-10\n",
    "print('Testing affine_backward function:')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU layer: forward\n",
    "Implement the forward pass for the ReLU activation function in the `relu_forward` function and test your implementation using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing relu_forward function:\n",
      "difference:  4.99999979802e-08\n"
     ]
    }
   ],
   "source": [
    "# Test the relu_forward function\n",
    "\n",
    "x = np.linspace(-0.5, 0.5, num=12).reshape(3, 4)\n",
    "\n",
    "out, _ = relu_forward(x)\n",
    "correct_out = np.array([[ 0.,          0.,          0.,          0.,        ],\n",
    "                        [ 0.,          0.,          0.04545455,  0.13636364,],\n",
    "                        [ 0.22727273,  0.31818182,  0.40909091,  0.5,       ]])\n",
    "\n",
    "# Compare your output with ours. The error should be around 5e-8\n",
    "print('Testing relu_forward function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU layer: backward\n",
    "Now implement the backward pass for the ReLU activation function in the `relu_backward` function and test your implementation using numeric gradient checking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing relu_backward function:\n",
      "dx error:  3.27563491363e-12\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(10, 10)\n",
    "dout = np.random.randn(*x.shape)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: relu_forward(x)[0], x, dout)\n",
    "\n",
    "_, cache = relu_forward(x)\n",
    "dx = relu_backward(dout, cache)\n",
    "\n",
    "# The error should be around 3e-12\n",
    "print('Testing relu_backward function:')\n",
    "print('dx error: ', rel_error(dx_num, dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Sandwich\" layers\n",
    "There are some common patterns of layers that are frequently used in neural nets. For example, affine layers are frequently followed by a ReLU nonlinearity. To make these common patterns easy, we define several convenience layers in the file `cs231n/layer_utils.py`.\n",
    "\n",
    "For now take a look at the `affine_relu_forward` and `affine_relu_backward` functions, and run the following to numerically gradient check the backward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_relu_forward:\n",
      "dx error:  2.29957917731e-11\n",
      "dw error:  8.16201110576e-11\n",
      "db error:  7.82672402146e-12\n"
     ]
    }
   ],
   "source": [
    "from cs231n.layer_utils import affine_relu_forward, affine_relu_backward\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(2, 3, 4)\n",
    "w = np.random.randn(12, 10)\n",
    "b = np.random.randn(10)\n",
    "dout = np.random.randn(2, 10)\n",
    "\n",
    "out, cache = affine_relu_forward(x, w, b)\n",
    "dx, dw, db = affine_relu_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: affine_relu_forward(x, w, b)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: affine_relu_forward(x, w, b)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: affine_relu_forward(x, w, b)[0], b, dout)\n",
    "\n",
    "print('Testing affine_relu_forward:')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss layers: Softmax and SVM\n",
    "You implemented these loss functions in the last assignment, so we'll give them to you for free here. You should still make sure you understand how they work by looking at the implementations in `cs231n/layers.py`.\n",
    "\n",
    "You can make sure that the implementations are correct by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing svm_loss:\n",
      "loss:  8.9996027491\n",
      "dx error:  1.40215660067e-09\n",
      "\n",
      "Testing softmax_loss:\n",
      "loss:  2.3025458445\n",
      "dx error:  9.38467316199e-09\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "num_classes, num_inputs = 10, 50\n",
    "x = 0.001 * np.random.randn(num_inputs, num_classes)\n",
    "y = np.random.randint(num_classes, size=num_inputs)\n",
    "\n",
    "dx_num = eval_numerical_gradient(lambda x: svm_loss(x, y)[0], x, verbose=False)\n",
    "loss, dx = svm_loss(x, y)\n",
    "\n",
    "# Test svm_loss function. Loss should be around 9 and dx error should be 1e-9\n",
    "print('Testing svm_loss:')\n",
    "print('loss: ', loss)\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "\n",
    "dx_num = eval_numerical_gradient(lambda x: softmax_loss(x, y)[0], x, verbose=False)\n",
    "loss, dx = softmax_loss(x, y)\n",
    "\n",
    "# Test softmax_loss function. Loss should be 2.3 and dx error should be 1e-8\n",
    "print('\\nTesting softmax_loss:')\n",
    "print('loss: ', loss)\n",
    "print('dx error: ', rel_error(dx_num, dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-layer network\n",
    "In the previous assignment you implemented a two-layer neural network in a single monolithic class. Now that you have implemented modular versions of the necessary layers, you will reimplement the two layer network using these modular implementations.\n",
    "\n",
    "Open the file `cs231n/classifiers/fc_net.py` and complete the implementation of the `TwoLayerNet` class. This class will serve as a model for the other networks you will implement in this assignment, so read through it to make sure you understand the API. You can run the cell below to test your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing initialization ... \n",
      "Testing test-time forward pass ... \n",
      "Testing training loss (no regularization)\n",
      "Running numeric gradient check with reg =  0.0\n",
      "W1 relative error: 1.22e-08\n",
      "W2 relative error: 3.12e-10\n",
      "b1 relative error: 9.83e-09\n",
      "b2 relative error: 4.33e-10\n",
      "Running numeric gradient check with reg =  0.7\n",
      "W1 relative error: 2.53e-07\n",
      "W2 relative error: 7.98e-08\n",
      "b1 relative error: 1.35e-08\n",
      "b2 relative error: 7.76e-10\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "N, D, H, C = 3, 5, 50, 7\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=N)\n",
    "\n",
    "std = 1e-3\n",
    "model = TwoLayerNet(input_dim=D, hidden_dim=H, num_classes=C, weight_scale=std)\n",
    "\n",
    "print('Testing initialization ... ')\n",
    "W1_std = abs(model.params['W1'].std() - std)\n",
    "b1 = model.params['b1']\n",
    "W2_std = abs(model.params['W2'].std() - std)\n",
    "b2 = model.params['b2']\n",
    "assert W1_std < std / 10, 'First layer weights do not seem right'\n",
    "assert np.all(b1 == 0), 'First layer biases do not seem right'\n",
    "assert W2_std < std / 10, 'Second layer weights do not seem right'\n",
    "assert np.all(b2 == 0), 'Second layer biases do not seem right'\n",
    "\n",
    "print('Testing test-time forward pass ... ')\n",
    "model.params['W1'] = np.linspace(-0.7, 0.3, num=D*H).reshape(D, H)\n",
    "model.params['b1'] = np.linspace(-0.1, 0.9, num=H)\n",
    "model.params['W2'] = np.linspace(-0.3, 0.4, num=H*C).reshape(H, C)\n",
    "model.params['b2'] = np.linspace(-0.9, 0.1, num=C)\n",
    "X = np.linspace(-5.5, 4.5, num=N*D).reshape(D, N).T\n",
    "scores = model.loss(X)\n",
    "correct_scores = np.asarray(\n",
    "  [[11.53165108,  12.2917344,   13.05181771,  13.81190102,  14.57198434, 15.33206765,  16.09215096],\n",
    "   [12.05769098,  12.74614105,  13.43459113,  14.1230412,   14.81149128, 15.49994135,  16.18839143],\n",
    "   [12.58373087,  13.20054771,  13.81736455,  14.43418138,  15.05099822, 15.66781506,  16.2846319 ]])\n",
    "scores_diff = np.abs(scores - correct_scores).sum()\n",
    "assert scores_diff < 1e-6, 'Problem with test-time forward pass'\n",
    "\n",
    "print('Testing training loss (no regularization)')\n",
    "y = np.asarray([0, 5, 1])\n",
    "loss, grads = model.loss(X, y)\n",
    "correct_loss = 3.4702243556\n",
    "assert abs(loss - correct_loss) < 1e-10, 'Problem with training-time loss'\n",
    "\n",
    "model.reg = 1.0\n",
    "loss, grads = model.loss(X, y)\n",
    "correct_loss = 26.5948426952\n",
    "assert abs(loss - correct_loss) < 1e-10, 'Problem with regularization loss'\n",
    "\n",
    "for reg in [0.0, 0.7]:\n",
    "  print('Running numeric gradient check with reg = ', reg)\n",
    "  model.reg = reg\n",
    "  loss, grads = model.loss(X, y)\n",
    "\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False)\n",
    "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solver\n",
    "In the previous assignment, the logic for training models was coupled to the models themselves. Following a more modular design, for this assignment we have split the logic for training models into a separate class.\n",
    "\n",
    "Open the file `cs231n/solver.py` and read through it to familiarize yourself with the API. After doing so, use a `Solver` instance to train a `TwoLayerNet` that achieves at least `50%` accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 4900) loss: 2.300161\n",
      "(Epoch 0 / 10) train acc: 0.139000; val_acc: 0.151000\n",
      "(Iteration 101 / 4900) loss: 1.777724\n",
      "(Iteration 201 / 4900) loss: 1.681457\n",
      "(Iteration 301 / 4900) loss: 1.515172\n",
      "(Iteration 401 / 4900) loss: 1.707817\n",
      "(Epoch 1 / 10) train acc: 0.438000; val_acc: 0.427000\n",
      "(Iteration 501 / 4900) loss: 1.747707\n",
      "(Iteration 601 / 4900) loss: 1.505152\n",
      "(Iteration 701 / 4900) loss: 1.686331\n",
      "(Iteration 801 / 4900) loss: 1.520211\n",
      "(Iteration 901 / 4900) loss: 1.520062\n",
      "(Epoch 2 / 10) train acc: 0.499000; val_acc: 0.477000\n",
      "(Iteration 1001 / 4900) loss: 1.428984\n",
      "(Iteration 1101 / 4900) loss: 1.392436\n",
      "(Iteration 1201 / 4900) loss: 1.276721\n",
      "(Iteration 1301 / 4900) loss: 1.548765\n",
      "(Iteration 1401 / 4900) loss: 1.441248\n",
      "(Epoch 3 / 10) train acc: 0.529000; val_acc: 0.486000\n",
      "(Iteration 1501 / 4900) loss: 1.199957\n",
      "(Iteration 1601 / 4900) loss: 1.197824\n",
      "(Iteration 1701 / 4900) loss: 1.301152\n",
      "(Iteration 1801 / 4900) loss: 1.341822\n",
      "(Iteration 1901 / 4900) loss: 1.061870\n",
      "(Epoch 4 / 10) train acc: 0.545000; val_acc: 0.504000\n",
      "(Iteration 2001 / 4900) loss: 1.338549\n",
      "(Iteration 2101 / 4900) loss: 1.261691\n",
      "(Iteration 2201 / 4900) loss: 1.332389\n",
      "(Iteration 2301 / 4900) loss: 1.296833\n",
      "(Iteration 2401 / 4900) loss: 1.186709\n",
      "(Epoch 5 / 10) train acc: 0.530000; val_acc: 0.517000\n",
      "(Iteration 2501 / 4900) loss: 1.151223\n",
      "(Iteration 2601 / 4900) loss: 1.269601\n",
      "(Iteration 2701 / 4900) loss: 1.167311\n",
      "(Iteration 2801 / 4900) loss: 1.182266\n",
      "(Iteration 2901 / 4900) loss: 1.365496\n",
      "(Epoch 6 / 10) train acc: 0.579000; val_acc: 0.508000\n",
      "(Iteration 3001 / 4900) loss: 1.254337\n",
      "(Iteration 3101 / 4900) loss: 1.107340\n",
      "(Iteration 3201 / 4900) loss: 0.972931\n",
      "(Iteration 3301 / 4900) loss: 1.219242\n",
      "(Iteration 3401 / 4900) loss: 1.241476\n",
      "(Epoch 7 / 10) train acc: 0.577000; val_acc: 0.531000\n",
      "(Iteration 3501 / 4900) loss: 1.325959\n",
      "(Iteration 3601 / 4900) loss: 0.997364\n",
      "(Iteration 3701 / 4900) loss: 1.042410\n",
      "(Iteration 3801 / 4900) loss: 1.067657\n",
      "(Iteration 3901 / 4900) loss: 1.204339\n",
      "(Epoch 8 / 10) train acc: 0.592000; val_acc: 0.540000\n",
      "(Iteration 4001 / 4900) loss: 1.042979\n",
      "(Iteration 4101 / 4900) loss: 1.180060\n",
      "(Iteration 4201 / 4900) loss: 1.182125\n",
      "(Iteration 4301 / 4900) loss: 1.073891\n",
      "(Iteration 4401 / 4900) loss: 1.022967\n",
      "(Epoch 9 / 10) train acc: 0.599000; val_acc: 0.523000\n",
      "(Iteration 4501 / 4900) loss: 1.127217\n",
      "(Iteration 4601 / 4900) loss: 1.254956\n",
      "(Iteration 4701 / 4900) loss: 1.202362\n",
      "(Iteration 4801 / 4900) loss: 1.037820\n",
      "(Epoch 10 / 10) train acc: 0.618000; val_acc: 0.532000\n",
      "test acc: 0.513000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet()\n",
    "solver = None\n",
    "\n",
    "##############################################################################\n",
    "# TODO: Use a Solver instance to train a TwoLayerNet that achieves at least  #\n",
    "# 50% accuracy on the validation set.                                        #\n",
    "##############################################################################\n",
    "solver = Solver(model, data,\n",
    "    update_rule='sgd',\n",
    "    optim_config={\n",
    "    'learning_rate': 1e-3,\n",
    "    },\n",
    "    lr_decay=0.8,\n",
    "    num_epochs=10, batch_size=100,\n",
    "    print_every=100)\n",
    "solver.train()\n",
    "scores = model.loss(data['X_test'])\n",
    "y_pred = np.argmax(scores, axis = 1)\n",
    "acc = np.mean(y_pred == data['y_test'])\n",
    "print('test acc: %f' %(acc))\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAALJCAYAAAAnCMuGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXtTaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe81cbe3d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to visualize training loss and train / val accuracy\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(solver.train_acc_history, '-o', label='train')\n",
    "plt.plot(solver.val_acc_history, '-o', label='val')\n",
    "plt.plot([0.5] * len(solver.val_acc_history), 'k--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.gcf().set_size_inches(15, 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer network\n",
    "Next you will implement a fully-connected network with an arbitrary number of hidden layers.\n",
    "\n",
    "Read through the `FullyConnectedNet` class in the file `cs231n/classifiers/fc_net.py`.\n",
    "\n",
    "Implement the initialization, the forward pass, and the backward pass. For the moment don't worry about implementing dropout or batch normalization; we will add those features soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial loss and gradient check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, run the following to check the initial loss and to gradient check the network both with and without regularization. Do the initial losses seem reasonable?\n",
    "\n",
    "For gradient checking, you should expect to see errors around 1e-6 or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running check with reg =  0\n",
      "Initial loss:  0.0\n",
      "Running check with reg =  3.14\n",
      "Initial loss:  0.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "N, D, H1, H2, C = 2, 15, 20, 30, 10\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=(N,))\n",
    "\n",
    "for reg in [0, 3.14]:\n",
    "  print('Running check with reg = ', reg)\n",
    "  model = FullyConnectedNet([H1, H2], input_dim=D, num_classes=C,\n",
    "                            reg=reg, weight_scale=5e-2, dtype=np.float64)\n",
    "\n",
    "  loss, grads = model.loss(X, y)\n",
    "  print('Initial loss: ', loss)\n",
    "\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False, h=1e-5)\n",
    "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another sanity check, make sure you can overfit a small dataset of 50 images. First we will try a three-layer network with 100 units in each hidden layer. You will need to tweak the learning rate and initialization scale, but you should be able to overfit and achieve 100% training accuracy within 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 40) loss: 0.000000\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'argmax'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fa909c059b75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m                 }\n\u001b[1;32m     21\u001b[0m          )\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CS231n/assignment2/cs231n/solver.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfirst_it\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlast_it\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mepoch_end\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 train_acc = self.check_accuracy(self.X_train, self.y_train,\n\u001b[0;32m--> 287\u001b[0;31m                     num_samples=self.num_train_samples)\n\u001b[0m\u001b[1;32m    288\u001b[0m                 val_acc = self.check_accuracy(self.X_val, self.y_val,\n\u001b[1;32m    289\u001b[0m                     num_samples=self.num_val_samples)\n",
      "\u001b[0;32m~/Desktop/CS231n/assignment2/cs231n/solver.py\u001b[0m in \u001b[0;36mcheck_accuracy\u001b[0;34m(self, X, y, num_samples, batch_size)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     \"\"\"\n\u001b[0;32m--> 963\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# a downstream library like 'pandas'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "# TODO: Use a three-layer Net to overfit 50 training examples.\n",
    "\n",
    "num_train = 50\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "weight_scale = 1e-2\n",
    "learning_rate = 1e-4\n",
    "model = FullyConnectedNet([100, 100],\n",
    "              weight_scale=weight_scale, dtype=np.float64)\n",
    "solver = Solver(model, small_data,\n",
    "                print_every=10, num_epochs=20, batch_size=25,\n",
    "                update_rule='sgd',\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate,\n",
    "                }\n",
    "         )\n",
    "solver.train()\n",
    "\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.title('Training loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to use a five-layer network with 100 units on each layer to overfit 50 training examples. Again you will have to adjust the learning rate and weight initialization, but you should be able to achieve 100% training accuracy within 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Use a five-layer Net to overfit 50 training examples.\n",
    "\n",
    "num_train = 50\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "learning_rate = 1e-3\n",
    "weight_scale = 1e-5\n",
    "model = FullyConnectedNet([100, 100, 100, 100],\n",
    "                weight_scale=weight_scale, dtype=np.float64)\n",
    "solver = Solver(model, small_data,\n",
    "                print_every=10, num_epochs=20, batch_size=25,\n",
    "                update_rule='sgd',\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate,\n",
    "                }\n",
    "         )\n",
    "solver.train()\n",
    "\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.title('Training loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inline question: \n",
    "Did you notice anything about the comparative difficulty of training the three-layer net vs training the five layer net?\n",
    "\n",
    "# Answer:\n",
    "[FILL THIS IN]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update rules\n",
    "So far we have used vanilla stochastic gradient descent (SGD) as our update rule. More sophisticated update rules can make it easier to train deep networks. We will implement a few of the most commonly used update rules and compare them to vanilla SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD+Momentum\n",
    "Stochastic gradient descent with momentum is a widely used update rule that tends to make deep networks converge faster than vanilla stochstic gradient descent.\n",
    "\n",
    "Open the file `cs231n/optim.py` and read the documentation at the top of the file to make sure you understand the API. Implement the SGD+momentum update rule in the function `sgd_momentum` and run the following to check your implementation. You should see errors less than 1e-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cs231n.optim import sgd_momentum\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "v = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-3, 'velocity': v}\n",
    "next_w, _ = sgd_momentum(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [ 0.1406,      0.20738947,  0.27417895,  0.34096842,  0.40775789],\n",
    "  [ 0.47454737,  0.54133684,  0.60812632,  0.67491579,  0.74170526],\n",
    "  [ 0.80849474,  0.87528421,  0.94207368,  1.00886316,  1.07565263],\n",
    "  [ 1.14244211,  1.20923158,  1.27602105,  1.34281053,  1.4096    ]])\n",
    "expected_velocity = np.asarray([\n",
    "  [ 0.5406,      0.55475789,  0.56891579, 0.58307368,  0.59723158],\n",
    "  [ 0.61138947,  0.62554737,  0.63970526,  0.65386316,  0.66802105],\n",
    "  [ 0.68217895,  0.69633684,  0.71049474,  0.72465263,  0.73881053],\n",
    "  [ 0.75296842,  0.76712632,  0.78128421,  0.79544211,  0.8096    ]])\n",
    "\n",
    "print('next_w error: ', rel_error(next_w, expected_next_w))\n",
    "print('velocity error: ', rel_error(expected_velocity, config['velocity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have done so, run the following to train a six-layer network with both SGD and SGD+momentum. You should see the SGD+momentum update rule converge faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_train = 4000\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "solvers = {}\n",
    "\n",
    "for update_rule in ['sgd', 'sgd_momentum']:\n",
    "  print('running with ', update_rule)\n",
    "  model = FullyConnectedNet([100, 100, 100, 100, 100], weight_scale=5e-2)\n",
    "\n",
    "  solver = Solver(model, small_data,\n",
    "                  num_epochs=5, batch_size=100,\n",
    "                  update_rule=update_rule,\n",
    "                  optim_config={\n",
    "                    'learning_rate': 1e-2,\n",
    "                  },\n",
    "                  verbose=True)\n",
    "  solvers[update_rule] = solver\n",
    "  solver.train()\n",
    "  print()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "for update_rule, solver in list(solvers.items()):\n",
    "  plt.subplot(3, 1, 1)\n",
    "  plt.plot(solver.loss_history, 'o', label=update_rule)\n",
    "  \n",
    "  plt.subplot(3, 1, 2)\n",
    "  plt.plot(solver.train_acc_history, '-o', label=update_rule)\n",
    "\n",
    "  plt.subplot(3, 1, 3)\n",
    "  plt.plot(solver.val_acc_history, '-o', label=update_rule)\n",
    "  \n",
    "for i in [1, 2, 3]:\n",
    "  plt.subplot(3, 1, i)\n",
    "  plt.legend(loc='upper center', ncol=4)\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSProp and Adam\n",
    "RMSProp [1] and Adam [2] are update rules that set per-parameter learning rates by using a running average of the second moments of gradients.\n",
    "\n",
    "In the file `cs231n/optim.py`, implement the RMSProp update rule in the `rmsprop` function and implement the Adam update rule in the `adam` function, and check your implementations using the tests below.\n",
    "\n",
    "[1] Tijmen Tieleman and Geoffrey Hinton. \"Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude.\" COURSERA: Neural Networks for Machine Learning 4 (2012).\n",
    "\n",
    "[2] Diederik Kingma and Jimmy Ba, \"Adam: A Method for Stochastic Optimization\", ICLR 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test RMSProp implementation; you should see errors less than 1e-7\n",
    "from cs231n.optim import rmsprop\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "cache = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-2, 'cache': cache}\n",
    "next_w, _ = rmsprop(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [-0.39223849, -0.34037513, -0.28849239, -0.23659121, -0.18467247],\n",
    "  [-0.132737,   -0.08078555, -0.02881884,  0.02316247,  0.07515774],\n",
    "  [ 0.12716641,  0.17918792,  0.23122175,  0.28326742,  0.33532447],\n",
    "  [ 0.38739248,  0.43947102,  0.49155973,  0.54365823,  0.59576619]])\n",
    "expected_cache = np.asarray([\n",
    "  [ 0.5976,      0.6126277,   0.6277108,   0.64284931,  0.65804321],\n",
    "  [ 0.67329252,  0.68859723,  0.70395734,  0.71937285,  0.73484377],\n",
    "  [ 0.75037008,  0.7659518,   0.78158892,  0.79728144,  0.81302936],\n",
    "  [ 0.82883269,  0.84469141,  0.86060554,  0.87657507,  0.8926    ]])\n",
    "\n",
    "print('next_w error: ', rel_error(expected_next_w, next_w))\n",
    "print('cache error: ', rel_error(expected_cache, config['cache']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test Adam implementation; you should see errors around 1e-7 or less\n",
    "from cs231n.optim import adam\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "m = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "v = np.linspace(0.7, 0.5, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-2, 'm': m, 'v': v, 't': 5}\n",
    "next_w, _ = adam(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [-0.40094747, -0.34836187, -0.29577703, -0.24319299, -0.19060977],\n",
    "  [-0.1380274,  -0.08544591, -0.03286534,  0.01971428,  0.0722929],\n",
    "  [ 0.1248705,   0.17744702,  0.23002243,  0.28259667,  0.33516969],\n",
    "  [ 0.38774145,  0.44031188,  0.49288093,  0.54544852,  0.59801459]])\n",
    "expected_v = np.asarray([\n",
    "  [ 0.69966,     0.68908382,  0.67851319,  0.66794809,  0.65738853,],\n",
    "  [ 0.64683452,  0.63628604,  0.6257431,   0.61520571,  0.60467385,],\n",
    "  [ 0.59414753,  0.58362676,  0.57311152,  0.56260183,  0.55209767,],\n",
    "  [ 0.54159906,  0.53110598,  0.52061845,  0.51013645,  0.49966,   ]])\n",
    "expected_m = np.asarray([\n",
    "  [ 0.48,        0.49947368,  0.51894737,  0.53842105,  0.55789474],\n",
    "  [ 0.57736842,  0.59684211,  0.61631579,  0.63578947,  0.65526316],\n",
    "  [ 0.67473684,  0.69421053,  0.71368421,  0.73315789,  0.75263158],\n",
    "  [ 0.77210526,  0.79157895,  0.81105263,  0.83052632,  0.85      ]])\n",
    "\n",
    "print('next_w error: ', rel_error(expected_next_w, next_w))\n",
    "print('v error: ', rel_error(expected_v, config['v']))\n",
    "print('m error: ', rel_error(expected_m, config['m']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have debugged your RMSProp and Adam implementations, run the following to train a pair of deep networks using these new update rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rates = {'rmsprop': 1e-4, 'adam': 1e-3}\n",
    "for update_rule in ['adam', 'rmsprop']:\n",
    "  print('running with ', update_rule)\n",
    "  model = FullyConnectedNet([100, 100, 100, 100, 100], weight_scale=5e-2)\n",
    "\n",
    "  solver = Solver(model, small_data,\n",
    "                  num_epochs=5, batch_size=100,\n",
    "                  update_rule=update_rule,\n",
    "                  optim_config={\n",
    "                    'learning_rate': learning_rates[update_rule]\n",
    "                  },\n",
    "                  verbose=True)\n",
    "  solvers[update_rule] = solver\n",
    "  solver.train()\n",
    "  print()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "for update_rule, solver in list(solvers.items()):\n",
    "  plt.subplot(3, 1, 1)\n",
    "  plt.plot(solver.loss_history, 'o', label=update_rule)\n",
    "  \n",
    "  plt.subplot(3, 1, 2)\n",
    "  plt.plot(solver.train_acc_history, '-o', label=update_rule)\n",
    "\n",
    "  plt.subplot(3, 1, 3)\n",
    "  plt.plot(solver.val_acc_history, '-o', label=update_rule)\n",
    "  \n",
    "for i in [1, 2, 3]:\n",
    "  plt.subplot(3, 1, i)\n",
    "  plt.legend(loc='upper center', ncol=4)\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a good model!\n",
    "Train the best fully-connected model that you can on CIFAR-10, storing your best model in the `best_model` variable. We require you to get at least 50% accuracy on the validation set using a fully-connected net.\n",
    "\n",
    "If you are careful it should be possible to get accuracies above 55%, but we don't require it for this part and won't assign extra credit for doing so. Later in the assignment we will ask you to train the best convolutional network that you can on CIFAR-10, and we would prefer that you spend your effort working on convolutional nets rather than fully-connected nets.\n",
    "\n",
    "You might find it useful to complete the `BatchNormalization.ipynb` and `Dropout.ipynb` notebooks before completing this part, since those techniques can help you train powerful models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_model = None\n",
    "################################################################################\n",
    "# TODO: Train the best FullyConnectedNet that you can on CIFAR-10. You might   #\n",
    "# batch normalization and dropout useful. Store your best model in the         #\n",
    "# best_model variable.                                                         #\n",
    "################################################################################\n",
    "pass\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test you model\n",
    "Run your best model on the validation and test sets. You should achieve above 50% accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(best_model.loss(data['X_test']), axis=1)\n",
    "y_val_pred = np.argmax(best_model.loss(data['X_val']), axis=1)\n",
    "print('Validation set accuracy: ', (y_val_pred == data['y_val']).mean())\n",
    "print('Test set accuracy: ', (y_test_pred == data['y_test']).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
